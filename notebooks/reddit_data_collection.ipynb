{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc790ca3-8921-498f-9567-eeec0f3182ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0e909-32cd-4f35-8be3-8b453e502b07",
   "metadata": {},
   "source": [
    "#### Due to the nature of scraping this data(apparently the current implementation of rate_limiting is bugged), I chunked up the data in multiple csvs.\n",
    "\n",
    "- reddit_questions.csv - 4615 rows - Quick proof of concept. Dirty Data. \n",
    "\n",
    "        -TrueAskReddit\n",
    "        -AskHistorians\n",
    "        -AskScienceFiction\n",
    "        -NoStupidQuestions\n",
    "        -relationship_advice\n",
    "        -AskProgramming\n",
    "        -AskAcademia\n",
    "        -AskPhilosophy\n",
    "        -AskMen\n",
    "        -AskWomen\n",
    "        -AskStatistics\n",
    "- reddit_questions2.csv - 2498 rows - Improved selection and cleaning\n",
    "\n",
    "        -TrueAskReddit\n",
    "        -AskHistorians\n",
    "        -AskScienceFiction\n",
    "        -NoStupidQuestions\n",
    "        -relationship_advice\n",
    "        -AskProgramming\n",
    "- reddit_questions3.csv - 1136 rows - Even More Improved selection and cleaning\n",
    "\n",
    "        -AskAcademia\n",
    "        -AskPhilosophy\n",
    "        -Ask_Politics\n",
    "- reddit_questions4.csv - 4168 rows  - Even More Improved selection and cleaning\n",
    "\n",
    "        -AskGames\n",
    "        -AskStatistics\n",
    "        -answers\n",
    "        -AskAnthropology\n",
    "        -relationship_advice\n",
    "        -AskSocialScience\n",
    "        -AskScience\n",
    "        -AskWomen\n",
    "        -AskMen\n",
    "        -AskScience\n",
    "        -AskReddit\n",
    "- reddit_questions5.csv - 2188 rows - Even More improved selection and cleaning\n",
    "\n",
    "        -TrueAskReddit\n",
    "        -AskHistorians\n",
    "        -NoStupidQuestions\n",
    "        -AskProgramming\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679be89d-9371-4c3a-8cf0-76287ae84b44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MissingRequiredAttributeException",
     "evalue": "Required configuration setting 'client_id' missing. \nThis setting can be provided in a praw.ini file, as a keyword argument to the Reddit class constructor, or as an environment variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingRequiredAttributeException\u001b[0m         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reddit \u001b[38;5;241m=\u001b[39m praw\u001b[38;5;241m.\u001b[39mReddit(ratelimit_seconds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\praw\\util\\deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[0;32m     37\u001b[0m     warn(\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     42\u001b[0m     )\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(_old_args, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\praw\\reddit.py:258\u001b[0m, in \u001b[0;36mReddit.__init__\u001b[1;34m(self, site_name, config_interpolation, requestor_class, requestor_kwargs, token_manager, **config_settings)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_agent\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, attribute) \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mCONFIG_NOT_SET, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 258\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MissingRequiredAttributeException(\n\u001b[0;32m    259\u001b[0m             required_message\u001b[38;5;241m.\u001b[39mformat(attribute)\n\u001b[0;32m    260\u001b[0m         )\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mclient_secret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mCONFIG_NOT_SET:\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingRequiredAttributeException(\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired_message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_secret\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFor installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m applications this value must be set to None via a keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to the Reddit class constructor.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m     )\n",
      "\u001b[1;31mMissingRequiredAttributeException\u001b[0m: Required configuration setting 'client_id' missing. \nThis setting can be provided in a praw.ini file, as a keyword argument to the Reddit class constructor, or as an environment variable."
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(ratelimit_seconds=600) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12864184-f4bd-47aa-b864-5144569d3529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subreddits = ['NoStupidQuestions',\n",
    "              'AskHistorians',\n",
    "              'TrueAskReddit',\n",
    "              'AskProgramming']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64161ac1-afd8-4d0d-b9a9-0fca17432953",
   "metadata": {},
   "source": [
    "The following is the crux of the reddit scraping. I go through each post and check for valid question-answer pairs and put them in the subreddit_dict in the following structure:\n",
    "\n",
    "{'subreddit name': \\[(Q1,A1),(Q2,A2),...],\n",
    " 'subreddit name 2': \\[(Q1,A1),(Q2,A2),...]'}\n",
    " \n",
    "\n",
    "\n",
    "* I'd like to thank Vijay for giving me the insight to check for 'stickied posts' to filter out moderator answers. Originally, I was just checking to see if 'Welcome' or 'welcome' is in the comment. Vijay also gave me the suggestion to use the ratelimit_seconds argument in the Reddit instantiation to help with my TooManyRequests errors *\n",
    "\n",
    "* I'd like thank Zubeir for giving me the insight on using a sleep mechanism to slow everything down*\n",
    "\n",
    "* I'd also like to thank Eric for his breakfast hour session. I downloaded that video, and it walked me through this whole process and significantly cut my time to make this*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81e880f-7fd3-44b1-ba9b-84b6c9b722c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleeping for 3 seconds. 618 qa pairs from  r/NoStupidQuestions\n",
      "sleeping for 3 seconds. 482 qa pairs from  r/AskHistorians\n",
      "sleeping for 3 seconds. 569 qa pairs from  r/TrueAskReddit\n",
      "sleeping for 3 seconds. 519 qa pairs from  r/AskProgramming\n"
     ]
    }
   ],
   "source": [
    "\n",
    "subreddit_dict = {}\n",
    "\n",
    "# Loop through subreddits\n",
    "for subreddit in subreddits:\n",
    "    \n",
    "    # storing questions in the following listas tuples:(Question, ANswer)\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # do a special case for r/relationship_advice\n",
    "    if subreddit == 'relationship_advice':\n",
    "        top_posts = reddit.subreddit(subreddit).top(limit=10000)\n",
    "    else:\n",
    "        top_posts = reddit.subreddit(subreddit).top(limit=1000)\n",
    "    # Loop through top posts in the subreddit    \n",
    "    for post in top_posts:\n",
    "        \n",
    "        # Sleep for .25 seconds between checking posts. I'm tired of getting kicked out\n",
    "        time.sleep(.25)\n",
    "        \n",
    "        # Make sure the post has a title and comments \n",
    "        if post.title and post.comments:\n",
    "            \n",
    "            title = post.title\n",
    "            # Make sure it's a question and try to not capture the questions directed explicitly at humans and no mentions of reddit\n",
    "            if (title[-1] == '?') and ('you' not in title) and ('You' not in title) and ('eddit' not in title):\n",
    "                # make the post title the question\n",
    "                question = title\n",
    "                #the first comment shuld be the most upvoted\n",
    "                top_comment = post.comments[0] \n",
    "                # Check if the top comment is a valid answer (not pinned or removed or deleted)\n",
    "                if (not top_comment.stickied) and (top_comment.body != '[removed]') and (top_comment.body != '[deleted]'):\n",
    "                    \n",
    "                    answer = top_comment.body\n",
    "                    qa_pairs.append((question, answer))\n",
    "                    #I used the following for debugging \n",
    "                    # print(f'Subreddit: {subreddit}')\n",
    "                    # print('-')\n",
    "                    # print(f'Question: {question}')\n",
    "                    # print('-')\n",
    "                    # print(f'Answer: {answer[:100]}')\n",
    "                    # print('!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "                    \n",
    "                    time.sleep(1)\n",
    "\n",
    "\n",
    "                      \n",
    "        #  Once we get 500 questions, that's all we need ( i need to add this, because it's possible that we check 1000 posts)\n",
    "        # if len(qa_pairs) == 500: \n",
    "        #     break\n",
    "    \n",
    "    # add qa pairs list as a value to the subreddit key\n",
    "    subreddit_dict[subreddit] = qa_pairs \n",
    "    print(f'sleeping for 3 seconds. {len(qa_pairs)} qa pairs from  r/{subreddit}')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c91ad-00cf-4da5-bb1d-29d150b47be8",
   "metadata": {},
   "source": [
    "Next step is to save all this information in a csv file. \n",
    "\n",
    "I use pandas, and unpack and repack my subreddit_dict into a better more easier object so that I can put it in the df that I create. \n",
    "\n",
    "There's definitely a better way to do this. I can perhaps make the df in the above loop itself. Or make the dict in such a way that i dont need to unpack/repack into a different object and therefore feed it directly into DataFrame constructor.\n",
    "\n",
    "This was an easy way for me to conceptualize and execute quickly. And it works how I want it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae92071-0e35-4625-a61c-bbb36e02a00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # My argument for not putting all my imports up top: I wanted to show my thought process from start to finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c15837-1290-4699-bf86-e2ed993d6c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f612391-32ff-4b16-b931-165363dc049d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleanedL_firstfive = []\n",
    "for subreddit in subreddit_dict.keys():\n",
    "    for t in subreddit_dict[subreddit]:\n",
    "        cleanedL_firstfive.append((subreddit,t[0],t[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a90aea5-40de-4c5d-828d-503c4fa61e58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleanedL_firstfive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d722e70b-67a2-4e36-99a3-474a456b1e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Subreddit'] = [t[0] for t in cleanedL_firstfive]\n",
    "df['Questions'] = [t[1] for t in cleanedL_firstfive]\n",
    "df['Human_Answer'] = [t[2] for t in cleanedL_firstfive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19243eca-7529-4b1d-b902-89174a588bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Human_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Why is it \"price gouging\" when people resell s...</td>\n",
       "      <td>Who said either of those was ok?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because they...</td>\n",
       "      <td>Nearly every night.  I don’t want life to just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anybody else hate how the Internet now fe...</td>\n",
       "      <td>Stumbleupon was awesome a decade ago.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because that...</td>\n",
       "      <td>Yep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Is it weird that my 35 year old friend is wait...</td>\n",
       "      <td>Meanwhile, in r/teenagers, there’s a 17 year o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subreddit                                          Questions  \\\n",
       "0  NoStupidQuestions  Why is it \"price gouging\" when people resell s...   \n",
       "1  NoStupidQuestions  Does anyone else stay up at night because they...   \n",
       "2  NoStupidQuestions  Does anybody else hate how the Internet now fe...   \n",
       "3  NoStupidQuestions  Does anyone else stay up at night because that...   \n",
       "4  NoStupidQuestions  Is it weird that my 35 year old friend is wait...   \n",
       "\n",
       "                                        Human_Answer  \n",
       "0                   Who said either of those was ok?  \n",
       "1  Nearly every night.  I don’t want life to just...  \n",
       "2              Stumbleupon was awesome a decade ago.  \n",
       "3                                                Yep  \n",
       "4  Meanwhile, in r/teenagers, there’s a 17 year o...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eddc5eb-d737-4faf-aa2f-fa65b6cb0183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/reddit_questions5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

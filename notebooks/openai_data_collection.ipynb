{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5c0086e-eefa-45b5-9ebc-c544773439bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728d68a8-b1b0-4c3f-b851-317e591b5740",
   "metadata": {},
   "source": [
    "#### I made multiple csvs...\n",
    "- gpt_answer_v1.csv - model: text-curie-001 - using prompts from  reddit_questions.csv - 4615 rows - Quick proof of concept. Really Dirty Data. \n",
    "     \n",
    "        -TrueAskReddit\n",
    "        -AskHistorians\n",
    "        -AskScienceFiction\n",
    "        -NoStupidQuestions\n",
    "        -relationship_advice\n",
    "        -AskProgramming\n",
    "        -AskAcademia\n",
    "        -AskPhilosophy\n",
    "        -AskMen\n",
    "        -AskWomen\n",
    "        -AskStatistics\n",
    "- gpt_answer_v2.csv - model: text-curie-001 - using prompts from  reddit_questions3.csv and reddit_questions4.csv - 5303 rows - Used for project\n",
    "\n",
    "\n",
    "        - AskAcademia\n",
    "        - AskPhilosophy\n",
    "        - Ask_Politics\n",
    "        - AskGames\n",
    "        - AskStatistics\n",
    "        - answers\n",
    "        - AskAnthropology\n",
    "        - relationship_advice\n",
    "        - AskSocialScience\n",
    "        - AskScience\n",
    "        - AskWomen\n",
    "        - AskMen\n",
    "        - AskScience\n",
    "        - AskReddit        \n",
    "- gpt_answer_v3.csv - model: text-curie-001 - using prompts from  reddit_questions5.csv - 2187 rows - Used for project\n",
    "\n",
    "\n",
    "        - NoStupidQuestions\n",
    "        - AskHistorians\n",
    "        - TrueAskReddit\n",
    "        - AskProgramming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "224ad040-9358-430b-befa-28f288f8b2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('data/reddit_questions3.csv')\n",
    "df4 = pd.read_csv('data/reddit_questions4.csv')\n",
    "df5 = pd.read_csv('data/reddit_questions5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f2ba8c7-425a-4139-b5b5-14a7ddf4ecbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df4.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df5.drop(columns=['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed3f72d3-b0ad-4c39-ae3a-0400012b760a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1136, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb759e14-4c4e-4385-aa48-baabaf5c42cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4168, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c98c60a-65de-43d9-97c1-e3136c50b8b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2188, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053796b8-01ed-4f1c-a507-529fe93229de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#d = pd.concat([df3, df4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efb4678-e915-48f4-94bb-a6d31b6bd295",
   "metadata": {},
   "source": [
    "I'd like to thank Alan for the great suggestion to use the dotenv library so that I can continue to work in jupyter lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f54f45e-cef6-4629-946d-46cded5f732b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c2cd185-eacd-418f-896d-b342dbc1b47f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai.api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2d76fc6-dd6e-43ef-8ddf-781671d03ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Human_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Why is it \"price gouging\" when people resell s...</td>\n",
       "      <td>Who said either of those was ok?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because they...</td>\n",
       "      <td>Nearly every night.  I don’t want life to just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anybody else hate how the Internet now fe...</td>\n",
       "      <td>Stumbleupon was awesome a decade ago.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because that...</td>\n",
       "      <td>Yep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Is it weird that my 35 year old friend is wait...</td>\n",
       "      <td>Meanwhile, in r/teenagers, there’s a 17 year o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subreddit                                          Questions  \\\n",
       "0  NoStupidQuestions  Why is it \"price gouging\" when people resell s...   \n",
       "1  NoStupidQuestions  Does anyone else stay up at night because they...   \n",
       "2  NoStupidQuestions  Does anybody else hate how the Internet now fe...   \n",
       "3  NoStupidQuestions  Does anyone else stay up at night because that...   \n",
       "4  NoStupidQuestions  Is it weird that my 35 year old friend is wait...   \n",
       "\n",
       "                                        Human_Answer  \n",
       "0                   Who said either of those was ok?  \n",
       "1  Nearly every night.  I don’t want life to just...  \n",
       "2              Stumbleupon was awesome a decade ago.  \n",
       "3                                                Yep  \n",
       "4  Meanwhile, in r/teenagers, there’s a 17 year o...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91cce64-8559-49b2-81f0-13a10ce1d0d0",
   "metadata": {},
   "source": [
    "Here is where I utilize openai's soon to be deprecated, Completion class to get my responses from chatgpt. I use the 'text-curie-001' model for cheap and fast execution. I'd like to thank Vijay for suggesting the batch size of 20. I need to do more research as to why he thinks that's the max batch size that completion could take. I'd also like to thank Eric again, for his breakfast hour class. \n",
    "\n",
    "Basically, I chunk up all the questions into batches, iterate through those batches, get the responses from each batch and put the output in a list (response_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b87893d8-a11f-496a-a0f7-f68055e28844",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished batch number 1/110\n",
      "finished batch number 2/110\n",
      "finished batch number 3/110\n",
      "finished batch number 4/110\n",
      "finished batch number 5/110\n",
      "finished batch number 6/110\n",
      "finished batch number 7/110\n",
      "finished batch number 8/110\n",
      "finished batch number 9/110\n",
      "finished batch number 10/110\n",
      "finished batch number 11/110\n",
      "finished batch number 12/110\n",
      "finished batch number 13/110\n",
      "finished batch number 14/110\n",
      "finished batch number 15/110\n",
      "finished batch number 16/110\n",
      "finished batch number 17/110\n",
      "finished batch number 18/110\n",
      "finished batch number 19/110\n",
      "finished batch number 20/110\n",
      "finished batch number 21/110\n",
      "finished batch number 22/110\n",
      "finished batch number 23/110\n",
      "finished batch number 24/110\n",
      "finished batch number 25/110\n",
      "finished batch number 26/110\n",
      "finished batch number 27/110\n",
      "finished batch number 28/110\n",
      "finished batch number 29/110\n",
      "finished batch number 30/110\n",
      "finished batch number 31/110\n",
      "finished batch number 32/110\n",
      "finished batch number 33/110\n",
      "finished batch number 34/110\n",
      "finished batch number 35/110\n",
      "finished batch number 36/110\n",
      "finished batch number 37/110\n",
      "finished batch number 38/110\n",
      "finished batch number 39/110\n",
      "finished batch number 40/110\n",
      "finished batch number 41/110\n",
      "finished batch number 42/110\n",
      "finished batch number 43/110\n",
      "finished batch number 44/110\n",
      "finished batch number 45/110\n",
      "finished batch number 46/110\n",
      "finished batch number 47/110\n",
      "finished batch number 48/110\n",
      "finished batch number 49/110\n",
      "finished batch number 50/110\n",
      "finished batch number 51/110\n",
      "finished batch number 52/110\n",
      "finished batch number 53/110\n",
      "finished batch number 54/110\n",
      "finished batch number 55/110\n",
      "finished batch number 56/110\n",
      "finished batch number 57/110\n",
      "finished batch number 58/110\n",
      "finished batch number 59/110\n",
      "finished batch number 60/110\n",
      "finished batch number 61/110\n",
      "finished batch number 62/110\n",
      "finished batch number 63/110\n",
      "finished batch number 64/110\n",
      "finished batch number 65/110\n",
      "finished batch number 66/110\n",
      "finished batch number 67/110\n",
      "finished batch number 68/110\n",
      "finished batch number 69/110\n",
      "finished batch number 70/110\n",
      "finished batch number 71/110\n",
      "finished batch number 72/110\n",
      "finished batch number 73/110\n",
      "finished batch number 74/110\n",
      "finished batch number 75/110\n",
      "finished batch number 76/110\n",
      "finished batch number 77/110\n",
      "finished batch number 78/110\n",
      "finished batch number 79/110\n",
      "finished batch number 80/110\n",
      "finished batch number 81/110\n",
      "finished batch number 82/110\n",
      "finished batch number 83/110\n",
      "finished batch number 84/110\n",
      "finished batch number 85/110\n",
      "finished batch number 86/110\n",
      "finished batch number 87/110\n",
      "finished batch number 88/110\n",
      "finished batch number 89/110\n",
      "finished batch number 90/110\n",
      "finished batch number 91/110\n",
      "finished batch number 92/110\n",
      "finished batch number 93/110\n",
      "finished batch number 94/110\n",
      "finished batch number 95/110\n",
      "finished batch number 96/110\n",
      "finished batch number 97/110\n",
      "finished batch number 98/110\n",
      "finished batch number 99/110\n",
      "finished batch number 100/110\n",
      "finished batch number 101/110\n",
      "finished batch number 102/110\n",
      "finished batch number 103/110\n",
      "finished batch number 104/110\n",
      "finished batch number 105/110\n",
      "finished batch number 106/110\n",
      "finished batch number 107/110\n",
      "finished batch number 108/110\n",
      "finished batch number 109/110\n",
      "finished batch number 110/110\n"
     ]
    }
   ],
   "source": [
    "# I could just use the Series object, but I feel more comfortable with lists\n",
    "questions = [question for question in df5['Questions']]\n",
    "# I was advised to use 20 as a batch size(I was advised that it was the max that Completion could take, but I couldnt find any info on it)\n",
    "batch_size = 20\n",
    "# Chunk up questions into a list of lists each inner list is of size batch size(20). The last list is the remainder.\n",
    "question_batches = [questions[i:i + batch_size] for i in range(0, len(questions), batch_size)]\n",
    "# Storage for the responses \n",
    "response_list = []\n",
    "# count and num_batches are just for me to measure time\n",
    "count = 0\n",
    "num_batches = len(question_batches)\n",
    "\n",
    "# go through each batch, and get the responses\n",
    "for batch in question_batches:\n",
    "    \n",
    "    # This is thanks to Eric from the breakfast hour\n",
    "    maries_response = openai.Completion.create(\n",
    "        model = 'text-curie-001', # good, cheap model\n",
    "        prompt = batch,\n",
    "        temperature = 0.6, # may want to play with this in the future\n",
    "        max_tokens = 250 # After some experimentation, I was satisfied with this\n",
    "    )\n",
    "   \n",
    "    # Just want a list of the responses -- nothing else. \n",
    "    # Hope is what is keeping the response order the same as the question order. \n",
    "    # But it isn't necessary for my implementation of the project. I'll explore in the future\n",
    "    batch_response = [res['text'].strip() for res in maries_response['choices']]\n",
    "    \n",
    "    # Append to the big list of responses\n",
    "    response_list += batch_response\n",
    "    \n",
    "\n",
    "    #sleep time\n",
    "    time.sleep(1)\n",
    "    #This is just for me to see progress\n",
    "    count+=1\n",
    "    print(f'finished batch number {count}/{num_batches}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4804e9ce-0172-45f8-ac4d-5843850fae2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2188"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4588a-c056-4979-b8a5-6608bf812347",
   "metadata": {},
   "source": [
    "Attaching the responses to the dataframe. Like I mentioned in the comments of the code, the question-answer pairs for the ai generated responses arent guarenteed to match up. I'm pretty sure they are, but I can't 100% guarentee that(I'd have to do more research on how COmpletions handles batch prompts). \n",
    "\n",
    "**However**, this question-answer pairing is NOT VITAL to my GA project goal. I just want to differentiate between chatgpt and human. the questions were just a convenient way for me to get an equal amount of training/test data for both classes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6f4cdb35-c390-4612-9b33-a58c51ae8f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5['Marie_Answer'] = response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5fe4b80-d5f4-4c05-967d-cd49bacef0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2188 entries, 0 to 2187\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Subreddit     2188 non-null   object\n",
      " 1   Questions     2188 non-null   object\n",
      " 2   Human_Answer  2188 non-null   object\n",
      " 3   Marie_Answer  2188 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 68.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "116572bf-71b0-4817-8392-a7d441664969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Human_Answer</th>\n",
       "      <th>Marie_Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Why is it \"price gouging\" when people resell s...</td>\n",
       "      <td>Who said either of those was ok?</td>\n",
       "      <td>One possible reason why it might be considered...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because they...</td>\n",
       "      <td>Nearly every night.  I don’t want life to just...</td>\n",
       "      <td>I stay up at night because I have a lot of fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anybody else hate how the Internet now fe...</td>\n",
       "      <td>Stumbleupon was awesome a decade ago.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Does anyone else stay up at night because that...</td>\n",
       "      <td>Yep</td>\n",
       "      <td>I do not know what you mean by \"stay up at nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoStupidQuestions</td>\n",
       "      <td>Is it weird that my 35 year old friend is wait...</td>\n",
       "      <td>Meanwhile, in r/teenagers, there’s a 17 year o...</td>\n",
       "      <td>It is not weird.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Subreddit                                          Questions  \\\n",
       "0  NoStupidQuestions  Why is it \"price gouging\" when people resell s...   \n",
       "1  NoStupidQuestions  Does anyone else stay up at night because they...   \n",
       "2  NoStupidQuestions  Does anybody else hate how the Internet now fe...   \n",
       "3  NoStupidQuestions  Does anyone else stay up at night because that...   \n",
       "4  NoStupidQuestions  Is it weird that my 35 year old friend is wait...   \n",
       "\n",
       "                                        Human_Answer  \\\n",
       "0                   Who said either of those was ok?   \n",
       "1  Nearly every night.  I don’t want life to just...   \n",
       "2              Stumbleupon was awesome a decade ago.   \n",
       "3                                                Yep   \n",
       "4  Meanwhile, in r/teenagers, there’s a 17 year o...   \n",
       "\n",
       "                                        Marie_Answer  \n",
       "0  One possible reason why it might be considered...  \n",
       "1  I stay up at night because I have a lot of fre...  \n",
       "2                                                     \n",
       "3  I do not know what you mean by \"stay up at nig...  \n",
       "4                                   It is not weird.  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a58a1-b845-473a-a2f7-c588ad314053",
   "metadata": {},
   "source": [
    "Writing to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e27bc49c-ed7d-4970-a66d-ea53f04eb0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df5.to_csv('data/gpt_answers_v3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
